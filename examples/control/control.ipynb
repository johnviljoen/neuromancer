{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install setuptools==61.0.0 pyts mlflow plum-dispatch==1.7.2 torchdiffeq\n",
    "# !pip install git+https://github.com/pnnl/neuromancer.git@master --ignore-requires-python --no-deps\n",
    "# Uncomment pip installs for Colab notebook    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad34cd0",
   "metadata": {},
   "source": [
    "# Control "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f5467",
   "metadata": {},
   "source": [
    "## Typical scenario. Off policy control learning\n",
    "\n",
    "In a typical real world control setting, due to cost and operational concerns, there is not an opportunity to directly interact with the system to learn a controller. In this scenario, the system is perturbed for some amount of time to collect measurements representative of the system state space, system identification is performed, and a controller is created based on the fitted model created via system identification. In the following cells we walk through the three stage process of generating data, system identification, and control policy learning using neuromancer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d651433",
   "metadata": {},
   "source": [
    "## Instantiate a system emulator from neuromancer.psl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuromancer.psl.nonautonomous import Actuator\n",
    "from neuromancer.dataset import DictDataset\n",
    "sys = Actuator()\n",
    "sys.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c6aab",
   "metadata": {},
   "source": [
    "# Define a simple neural ODE model of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuromancer.system import Node, System\n",
    "from neuromancer.modules import blocks\n",
    "from neuromancer.dynamics import integrators\n",
    "import torch\n",
    "\n",
    "dx = blocks.MLP(sys.nx + sys.nu, sys.nx, bias=True, linear_map=torch.nn.Linear, nonlin=torch.nn.ELU,\n",
    "              hsizes=[20 for h in range(3)])\n",
    "interp_u = lambda tq, t, u: u\n",
    "integrator = integrators.Euler(dx, h=torch.tensor(0.1), interp_u=interp_u)\n",
    "system_node = Node(integrator, ['xn', 'U'], ['xn'])\n",
    "model = System([system_node])\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968d59d",
   "metadata": {},
   "source": [
    "# Generate datasets representative of system behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data, test_data = [sys.simulate(nsim=1000) for i in range(3)]\n",
    "sys.show()\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_data, dev_data, test_data = [sys.normalize(d) for d in [train_data, dev_data, test_data]]\n",
    "sys.show(train_data)\n",
    "# Set up the data to be in samples of 10 contiguous time steps (100 samples with 10 time steps each last dim is dimension of the measured variable)\n",
    "for d in [train_data, dev_data]:\n",
    "    d['X'] = d['X'].reshape(100, 10, 3)\n",
    "    d['U'] = d['U'].reshape(100, 10, 3)\n",
    "    d['Y'] = d['Y'].reshape(100, 10, 3)\n",
    "    d['xn'] = d['X'][:, 0:1, :] # Add an initial condition to start the system loop\n",
    "    d['Time'] = d['Time'].reshape(100, -1)\n",
    "\n",
    "train_dataset, dev_dataset, = [DictDataset(d, name=n) for d, n in zip([train_data, dev_data], ['train', 'dev'])]\n",
    "train_loader, dev_loader, test_loader = [DataLoader(d, batch_size=100, collate_fn=d.collate_fn, shuffle=True) for d in [train_dataset, dev_dataset, dev_dataset]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad4d33",
   "metadata": {},
   "source": [
    "# Define the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuromancer.constraint import variable\n",
    "from neuromancer.problem import Problem\n",
    "from neuromancer.loss import PenaltyLoss\n",
    "\n",
    "# Nstep rollout predictions from the model\n",
    "xpred = variable('xn')[:, :-1, :]\n",
    "# Ground truth data\n",
    "xtrue = variable('X')\n",
    "\n",
    "loss = (xpred == xtrue) ^ 2\n",
    "loss.update_name('loss')\n",
    "\n",
    "obj = PenaltyLoss([loss], [])\n",
    "problem = Problem([model], obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c6c5f",
   "metadata": {},
   "source": [
    "## Minimize the system identification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuromancer.trainer import Trainer\n",
    "import torch.optim as optim\n",
    "\n",
    "opt = optim.Adam(model.parameters(), 0.001)\n",
    "trainer = Trainer(problem, train_loader, dev_loader, test_loader, opt,\n",
    "                  epochs=1000,\n",
    "                  patience=300,\n",
    "                  train_metric='train_loss',\n",
    "                  dev_metric='dev_loss',\n",
    "                  test_metric='test_loss',\n",
    "                  eval_metric='dev_loss')\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58dbdf",
   "metadata": {},
   "source": [
    "## Evaluate system model on 1000 time step rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f33785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test_data = sys.normalize(sys.simulate(nsim=1000))\n",
    "print({k: v.shape for k, v in test_data.items()})\n",
    "\n",
    "test_data['X'] = test_data['X'].reshape(1, *test_data['X'].shape)\n",
    "test_data['U'] = test_data['U'].reshape(1, *test_data['U'].shape)\n",
    "test_data['xn'] = test_data['X'][:, 0:1, :]\n",
    "test_data = {k: torch.tensor(v, dtype=torch.float32) for k, v in test_data.items()}\n",
    "test_output = model(test_data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fix, ax = plt.subplots(nrows=3)\n",
    "for v in range(3):\n",
    "    ax[v].plot(test_output['xn'][0, :-1, v].detach().numpy(), label='pred')\n",
    "    ax[v].plot(test_data['X'][0, :, v].detach().numpy(), label='true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c61c8",
   "metadata": {},
   "source": [
    "## Create a closed loop system using the system model and a parametrized control policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, nu = sys.nx, sys.nu\n",
    "\n",
    "class Policy(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, insize, outsize):\n",
    "        super().__init__()\n",
    "        self.net = blocks.MLP(insize, outsize, bias=True, hsizes=[20, 20, 20])\n",
    "\n",
    "    def forward(self, x, R):\n",
    "        features = torch.cat([x, R], dim=-1)\n",
    "        return self.net(features)\n",
    "\n",
    "insize = 2*nx\n",
    "policy = Policy(insize, nu)\n",
    "policy_node = Node(policy, ['xn', 'R'], ['U'], name='policy')\n",
    "cl_system = System([policy_node, system_node])\n",
    "cl_system.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282e8de",
   "metadata": {},
   "source": [
    "## Optimizing the control policy\n",
    "\n",
    "For this simple Actuator system the same dataset can be used for learning a control policy as we used to learn the system model. Here we wish to optimize  controlling the system to some reference trajectory R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DictDataset({'R': train_data['X'], 'X': train_data['X'], 'xn': train_data['xn']}, name='train')\n",
    "dev_dataset = DictDataset({'R': dev_data['X'], 'X': train_data['X'], 'xn': dev_data['xn']}, name='dev')\n",
    "train_loader, dev_loader = [DataLoader(d, batch_size=100, collate_fn=d.collate_fn, shuffle=True) for d in [train_dataset, dev_dataset]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bfdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(policy.parameters(), 0.01)\n",
    "\n",
    "tru = variable('xn')[:, 1:, :]\n",
    "ref = variable('R')\n",
    "u = variable('U')\n",
    "loss = (ref == tru) ^ 2\n",
    "loss.update_name('loss')\n",
    "\n",
    "obj = PenaltyLoss([loss], [])\n",
    "problem = Problem([cl_system], obj)\n",
    "\n",
    "logout = ['loss']\n",
    "trainer = Trainer(problem, train_loader, dev_loader, dev_loader, opt,\n",
    "                  epochs=1000,\n",
    "                  patience=1000,\n",
    "                  train_metric='train_loss',\n",
    "                  dev_metric='dev_loss',\n",
    "                  test_metric='dev_loss',\n",
    "                  eval_metric='dev_loss')\n",
    "\n",
    "best_model = trainer.train()\n",
    "trainer.model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864741d",
   "metadata": {},
   "source": [
    "## Evaluating the model on the true system\n",
    "\n",
    "With the optional pytorch backend for the original ODE system we can now swap out our learned model to evaluate the learned control policy on the original system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.change_backend('torch')\n",
    "# We will have to denormalize the policy actions according to the system stats\n",
    "# Conversely we will have to normalize the system states according to the system stats to hand to the policy\n",
    "\n",
    "def norm(x):\n",
    "    return sys.normalize(x, key='X')\n",
    "\n",
    "def denorm(u):\n",
    "    return sys.denormalize(u, key='U')\n",
    "\n",
    "normnode = Node(norm, ['xsys'], ['xn'], name='norm')\n",
    "denormnode = Node(denorm, ['U'], ['u'], name='denorm')\n",
    "sysnode = Node(sys, ['xsys', 'u'], ['xsys'], name='actuator')\n",
    "test_system = System([normnode, policy_node, denormnode, sysnode])\n",
    "# test_system.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34d211",
   "metadata": {},
   "source": [
    "## Evaluate on 1000 steps with a new reference trajectory distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e190864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuromancer.psl.signals import sines, step, arma, spline\n",
    "import numpy as np\n",
    "references = spline(nsim=1000, d=sys.nx, min=sys.stats['X']['min'], max=sys.stats['X']['max'])\n",
    "plt.plot(references)\n",
    "test_data = {'R': torch.tensor(sys.normalize(references, key='X'), dtype=torch.float32).unsqueeze(0), 'xsys': sys.get_x0().reshape(1, 1, -1),\n",
    "            'Time': (np.arange(1000)*sys.ts).reshape(1, 1000, 1)}\n",
    "print({k: v.shape for k, v in test_data.items()})\n",
    "test_system.nsteps=1000\n",
    "with torch.no_grad():\n",
    "    test_out = test_system(test_data)\n",
    "\n",
    "print({k: v.shape for k, v in test_out.items()})\n",
    "fix, ax = plt.subplots(nrows=3)\n",
    "for v in range(3):\n",
    "    ax[v].plot(test_out['xn'][0, 1:, v].detach().numpy(), label='pred')\n",
    "    ax[v].plot(test_data['R'][0, :, v].detach().numpy(), label='true')\n",
    "plt.legend()\n",
    "plt.savefig('control.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40087e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
