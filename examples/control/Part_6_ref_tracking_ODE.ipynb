{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e017c9a3",
   "metadata": {},
   "source": [
    "# Reference tracking nonlinear ODE\n",
    "\n",
    "Neural Ordinary Differentiable predictive control (NO-DPC)\n",
    "\n",
    "Reference tracking of nonlinear ODE system with explicit neural control policy via DPC algorithm\n",
    "\n",
    "system: Two Tank model  \n",
    "example inspired by: https://apmonitor.com/do/index.php/Main/LevelControl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ffdcd",
   "metadata": {},
   "source": [
    "## NeuroMANCER and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac7825",
   "metadata": {},
   "source": [
    "### Install (Colab only)\n",
    "Skip this step when running locally.\n",
    "\n",
    "We need to install a more recent version of matplotlib than is offered in the default Colab environment. After running the cell 1 for the first time in a new Colab runtime, you will see the prompt: \"You must restart the runtime in order to use newly installed versions.\" After restarting, the correct version of matplotlib will be loaded for the duration of the current runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install setuptools==61.0.0 casadi mlflow torchdiffeq dill pyts plum-dispatch==1.7.3 --user\n",
    "!pip install git+https://github.com/pnnl/neuromancer.git@master --ignore-requires-python --no-deps --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9b6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import neuromancer.psl as psl\n",
    "from neuromancer.system import Node, System\n",
    "from neuromancer.modules import blocks\n",
    "from neuromancer.modules.activations import activations\n",
    "from neuromancer.dataset import DictDataset\n",
    "from neuromancer.constraint import variable\n",
    "from neuromancer.loss import PenaltyLoss\n",
    "from neuromancer.problem import Problem\n",
    "from neuromancer.trainer import Trainer\n",
    "from neuromancer.dynamics import ode, integrators\n",
    "from neuromancer.plot import pltCL, pltPhase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1b7ed",
   "metadata": {},
   "source": [
    "## Ground truth system model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd824de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_model = psl.nonautonomous.TwoTank()\n",
    "# sampling rate\n",
    "ts = 10*gt_model.params[1]['ts']\n",
    "# problem dimensions\n",
    "nx = gt_model.nx    # number of states\n",
    "nu = gt_model.nu    # number of control inputs\n",
    "nref = nx           # number of references\n",
    "# constraints bounds\n",
    "umin = 0\n",
    "umax = 1.\n",
    "xmin = 0\n",
    "xmax = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa938158",
   "metadata": {},
   "source": [
    "## Training dataset generation\n",
    "\n",
    "For a training dataset we randomly sample points away from the origin of the 2D space the systemn operates in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74ee8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 50  # prediction horizon\n",
    "n_samples = 2000    # number of sampled scenarios\n",
    "\n",
    "#  sampled references for training the policy\n",
    "list_refs = [torch.rand(1, 1)*torch.ones(nsteps+1, nref) for k in range(n_samples)]\n",
    "ref = torch.cat(list_refs)\n",
    "batched_ref = ref.reshape([n_samples, nsteps+1, nref])\n",
    "# Training dataset\n",
    "train_data = DictDataset({'x': torch.rand(n_samples, 1, nx),\n",
    "                          'r': batched_ref}, name='train')\n",
    "\n",
    "# references for dev set\n",
    "list_refs = [torch.rand(1, 1)*torch.ones(nsteps+1, nref) for k in range(n_samples)]\n",
    "ref = torch.cat(list_refs)\n",
    "batched_ref = ref.reshape([n_samples, nsteps+1, nref])\n",
    "# Development dataset\n",
    "dev_data = DictDataset({'x': torch.rand(n_samples, 1, nx),\n",
    "                        'r': batched_ref}, name='dev')\n",
    "\n",
    "# torch dataloaders\n",
    "batch_size = 200\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           collate_fn=train_data.collate_fn,\n",
    "                                           shuffle=False)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_data, batch_size=batch_size,\n",
    "                                         collate_fn=dev_data.collate_fn,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387d6a2",
   "metadata": {},
   "source": [
    "## System model and Control policy in Neuromancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149f7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# white-box ODE model with no-plant model mismatch\n",
    "two_tank_ode = ode.TwoTankParam()\n",
    "two_tank_ode.c1 = nn.Parameter(torch.tensor(gt_model.c1), requires_grad=False)\n",
    "two_tank_ode.c2 = nn.Parameter(torch.tensor(gt_model.c2), requires_grad=False)\n",
    "\n",
    "# integrate continuous time ODE\n",
    "interp_u = lambda tq, t, u: u\n",
    "integrator = integrators.RK4(two_tank_ode, h=torch.tensor(ts), interp_u=interp_u)\n",
    "# symbolic system model\n",
    "model = Node(integrator, ['x', 'u'], ['x'], name='model')\n",
    "\n",
    "# concatenate control parameters x and r into a vector xi\n",
    "cat_fun = lambda x, r: torch.cat([x, r], dim=-1)\n",
    "params = Node(cat_fun, ['x', 'r'], ['xi'], name='params')\n",
    "\n",
    "# neural net control policy\n",
    "net = blocks.MLP_bounds(insize=nx + nref, outsize=nu, hsizes=[32, 32],\n",
    "                    nonlin=activations['gelu'], min=umin, max=umax)\n",
    "policy = Node(net, ['xi'], ['u'], name='policy')\n",
    "\n",
    "# closed-loop system model\n",
    "cl_system = System([params, policy, model], nsteps=nsteps)\n",
    "# cl_system.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b33d60",
   "metadata": {},
   "source": [
    "## Differentiable Predictive Control objectives and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eccb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "x = variable('x')\n",
    "ref = variable(\"r\")\n",
    "# objectives\n",
    "regulation_loss = 5. * ((x == ref) ^ 2)  # target posistion\n",
    "# constraints\n",
    "state_lower_bound_penalty = 10.*(x > xmin)\n",
    "state_upper_bound_penalty = 10.*(x < xmax)\n",
    "terminal_lower_bound_penalty = 10.*(x[:, [-1], :] > ref-0.01)\n",
    "terminal_upper_bound_penalty = 10.*(x[:, [-1], :] < ref+0.01)\n",
    "# objectives and constraints names for nicer plot\n",
    "regulation_loss.name = 'state_loss'\n",
    "state_lower_bound_penalty.name = 'x_min'\n",
    "state_upper_bound_penalty.name = 'x_max'\n",
    "terminal_lower_bound_penalty.name = 'y_N_min'\n",
    "terminal_upper_bound_penalty.name = 'y_N_max'\n",
    "# list of constraints and objectives\n",
    "objectives = [regulation_loss]\n",
    "constraints = [\n",
    "    state_lower_bound_penalty,\n",
    "    state_upper_bound_penalty,\n",
    "    terminal_lower_bound_penalty,\n",
    "    terminal_upper_bound_penalty,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d77bde",
   "metadata": {},
   "source": [
    "## Differentiable optimal control problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab1f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (x_k, r_k) -> parameters (xi_k) -> policy (u_k) -> dynamics (x_k+1)\n",
    "components = [cl_system]\n",
    "# create constrained optimization loss\n",
    "loss = PenaltyLoss(objectives, constraints)\n",
    "# construct constrained optimization problem\n",
    "problem = Problem(components, loss)\n",
    "# plot computational graph\n",
    "# problem.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ef578",
   "metadata": {},
   "source": [
    "## Solve the problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467aec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 5.763517379760742\n",
      "epoch: 1  train_loss: 4.963501930236816\n",
      "epoch: 2  train_loss: 4.360177040100098\n",
      "epoch: 3  train_loss: 4.046024322509766\n",
      "epoch: 4  train_loss: 3.909597396850586\n",
      "epoch: 5  train_loss: 3.7723021507263184\n",
      "epoch: 6  train_loss: 3.4720301628112793\n",
      "epoch: 7  train_loss: 3.1941134929656982\n",
      "epoch: 8  train_loss: 2.9982266426086426\n",
      "epoch: 9  train_loss: 2.8521716594696045\n",
      "epoch: 10  train_loss: 2.7708382606506348\n",
      "epoch: 11  train_loss: 2.72204327583313\n",
      "epoch: 12  train_loss: 2.6895968914031982\n",
      "epoch: 13  train_loss: 2.665266990661621\n",
      "epoch: 14  train_loss: 2.6431736946105957\n",
      "epoch: 15  train_loss: 2.62302303314209\n",
      "epoch: 16  train_loss: 2.60476016998291\n",
      "epoch: 17  train_loss: 2.5899553298950195\n",
      "epoch: 18  train_loss: 2.5768091678619385\n",
      "epoch: 19  train_loss: 2.566129446029663\n",
      "epoch: 20  train_loss: 2.556889772415161\n",
      "epoch: 21  train_loss: 2.548978805541992\n",
      "epoch: 22  train_loss: 2.5429294109344482\n",
      "epoch: 23  train_loss: 2.538062810897827\n",
      "epoch: 24  train_loss: 2.5336570739746094\n",
      "epoch: 25  train_loss: 2.5297980308532715\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=0.002)\n",
    "#  Neuromancer trainer\n",
    "trainer = Trainer(\n",
    "    problem,\n",
    "    train_loader, dev_loader, dev_loader,\n",
    "    optimizer,\n",
    "    epochs=100,\n",
    "    train_metric='train_loss',\n",
    "    eval_metric='dev_loss',\n",
    "    warmup=50,\n",
    ")\n",
    "# Train control policy\n",
    "best_model = trainer.train()\n",
    "# load best trained model\n",
    "trainer.model.load_state_dict(best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1360ed",
   "metadata": {},
   "source": [
    "# Evaluate best model on a system rollout \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 750\n",
    "step_length = 150\n",
    "# generate reference\n",
    "np_refs = psl.signals.step(nsteps+1, 1, min=xmin, max=xmax, randsteps=5)\n",
    "R = torch.tensor(np_refs, dtype=torch.float32).reshape(1, nsteps+1, 1)\n",
    "torch_ref = torch.cat([R, R], dim=-1)\n",
    "# generate initial data for closed loop simulation\n",
    "data = {'x': torch.rand(1, 1, nx, dtype=torch.float32),\n",
    "        'r': torch_ref}\n",
    "cl_system.nsteps = nsteps\n",
    "# perform closed-loop simulation\n",
    "trajectories = cl_system(data)\n",
    "\n",
    "# constraints bounds\n",
    "Umin = umin * np.ones([nsteps, nu])\n",
    "Umax = umax * np.ones([nsteps, nu])\n",
    "Xmin = xmin * np.ones([nsteps+1, nx])\n",
    "Xmax = xmax * np.ones([nsteps+1, nx])\n",
    "# plot closed loop trajectories\n",
    "pltCL(Y=trajectories['x'].detach().reshape(nsteps + 1, nx),\n",
    "      R=trajectories['r'].detach().reshape(nsteps + 1, nref),\n",
    "      U=trajectories['u'].detach().reshape(nsteps, nu),\n",
    "      Umin=Umin, Umax=Umax, Ymin=Xmin, Ymax=Xmax,\n",
    "      figname='cl.png')\n",
    "# plot phase portrait\n",
    "pltPhase(X=trajectories['x'].detach().reshape(nsteps + 1, nx),\n",
    "         figname='phase.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18fbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b909f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromancer",
   "language": "python",
   "name": "neuromancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
